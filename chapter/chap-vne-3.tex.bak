\chapter{面向媒体业务的虚拟网络嵌入研究}
\label{chap:vne}
\section{引言}
1.简要介绍大背景
2.简要介绍本部分内容
\section{相关研究}
国内外研究现状
\section{面向媒体业务的虚拟网络嵌入算法设计}
\subsection{整体架构}
本章提出了面向媒体业务的虚拟网络嵌入算法，~MSO-VNE~。该算法的整体架构如图\ref{fig:procedure}所示。~MSO-VNE~算法在进行虚拟网络嵌入时，主要分以下两个阶段:
\par
\textbf{1）全局处理}
\par
在全局处理阶段，采用“中心式”的架构，对原始的虚拟网络请求运用节点聚类分析和分割处理，将原始的虚拟网络子请求划分为多个子请求。接着，每个子请求会被分派到相应区域的底层物理网络中进行局部嵌入。相比原始的虚拟网络请求，新的子请求具有更少的节点和更简单的链路，因此，各个子请求的嵌入处理过程会被大大简化，映射效率也会被大大提升。
\par
\textbf{2）局部嵌入}
\par
局部嵌入阶段是真正的嵌入和映射处理阶段，它的处理对象是全局处理阶段分割而成的所有子请求。由于子请求相比原始的请求有更小的规模，因此，局部嵌入计算的复杂度将大大减小。在这个阶段，多个子请求可以“分布式”地在各自区域的底层物理网络中执行真正的嵌入处理，进一步提高了嵌入效率。另外，在局部嵌入中，我们采用了动态服务均衡分析以辅助嵌入，提高了底层物理网络的资源利用率。
\par
在下面的章节中，我们将详细介绍面向媒体业务的虚拟网络嵌入算法~MSO-VNE~。
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{procedure.eps}
\caption{面向媒体业务的虚拟网络嵌入算法整体架构}
\label{fig:procedure}
\end{figure}

\subsection{网络模型}
\textbf{1）虚拟网络请求}
\par
虚拟网络请求可建模为带权重的无向图~$G^v=(N^v,E^v)$~，其中~$N^v$~是虚拟节点集合，而~$E^v$~是虚拟链路集合。定义虚拟节点~$n^v$~的邻居节点集合为~$N^v(n^v)$~，定义连接到节点~$n^v$~的链路集合为~$E^v(n^v)$~。虚拟网络请求中的虚拟节点和虚拟链路都与他们的需求限制相关联。我们定义虚拟网络请求中，虚拟节点的需求限制信息包括：地理位置~$L^v$~、存储容量~$S^v$~、磁盘~I/O~速率~$I^v$~、CPU~数量~$P^v$~和内存大小~$M^v$~，虚拟链路的需求限制包括：带宽~$B^v$~、 延迟~$D^v$~和延迟抖动~$J^v$~。表格\ref{tab:constraint}详细列举出了虚拟网络请求需求限制，并为各个需求限制定义权重影响因子以计算虚拟节点和虚拟链路的归一化需求限制。因此，虚拟网络请求中虚拟节点~$n^v$~的归一化资源~$c^v(n^v)$~可表示为: $$c^v(n^v)=S^v(n^v)\cdot w_S^n + I^v(n^v) \cdot w_I^n + P^v(n^v)\cdot w_P^n + M^v(n^v)\cdot w_M^n$$
\par
虚拟链路~$e^v$~的归一化资源~$b^v(e^v)$~可表示为:
$$b^v(e^v)=B^v(e^v)\cdot w_B^e + D^v(e^v) \cdot w_D^e + J^v(e^v)\cdot w_J^e$$
\par
其中需求限制中的地理位置限制主要用于节点聚类分析，不用考虑在节点需求的归一化表示中。

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{虚拟节点需求限制} & \multicolumn{3}{|c|}{虚拟链路需求限制}\\\hline
因素 & 符号表示 & 权重因子 & 因素 & 符号表示 & 权重因子\\\hline
地理位置 & $L^v$ &         & 带宽 &  $B^v$   & $w_B^e$ \\\hline
存储容量 & $S^v$ & $w_S^n$ & 延迟 &  $D^v$   & $w_D^e$ \\\hline
磁盘~I/O & $I^v$  & $w_I^n$ & 延迟抖动 & $J^v$ & $w_J^e$ \\\hline
CPU~数量 & $P^v$  & $w_P^n$ &           &       &      \\\hline
内存大小 & $M^v$ & $w_M^n$ &            &       &     \\\hline
归一化资源 & $c^v$ &       & 归一化资源& $b^v$ &       \\\hline
\multicolumn{3}{|c|}{$w_S^n + w_I^n + w_P^n + w_M^n = 1$} & \multicolumn{3}{|c|}{$w_B^e + w_D^e + w_J^e = 1$}\\\hline
\end{tabular}
\caption{虚拟网络请求的需求限制}
\label{tab:constraint}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{节点资源限制} & \multicolumn{3}{|c|}{链路资源限制}\\\hline
因素 & 符号表示 & 权重因子 & 因素 & 符号表示 & 权重因子\\\hline
地理位置 & $L^s$ &         & 带宽 &  $B^s$   & $w_B^e$ \\\hline
存储容量 & $S^s$ & $w_S^n$ & 延迟 &  $D^s$   & $w_D^e$ \\\hline
磁盘~I/O & $I^s$  & $w_I^n$ & 延迟抖动 & $J^s$ & $w_J^e$ \\\hline
CPU~数量 & $P^s$  & $w_P^n$ &           &       &      \\\hline
内存大小 & $M^s$ & $w_M^n$ &            &       &     \\\hline
归一化资源 & $c^s$ &       & 归一化资源& $b^s$ &       \\\hline
\multicolumn{3}{|c|}{$w_S^n + w_I^n + w_P^n + w_M^n = 1$} & \multicolumn{3}{|c|}{$w_B^e + w_D^e + w_J^e = 1$}\\\hline
\end{tabular}
\caption{底层物理网络的资源限制}
\label{tab:resource}
\end{table}

\par
\textbf{2）底层物理网络}
\par
同样地，底层物理网络可建模为带权重的无向图~$G^s=(N^s,E^s)$~，底层物理网络的第~$i$~个区域可表示为无向图~$G_i^s=(N_i^s,E_i^s)$~，其中~$N_i^s$~表示区域~$i$~内的节点集合，而~$E_i^s$~表示区域~$i$~ 内的链路集合。定义节点~$n^s$~的邻居节点集合为~$N^s(n^s)$~，定义连接到节点~$n^s$~的链路集合为~$E^s(n^s)$~。底层物理网络中的节点和链路都与他们的资源限制相关联。在底层物理网络中，我们定义节点的资源限制信息包括：地理的位置~$L^s$~、 存储容量~$S^s$~、 磁盘~I/O~ 速率~$I^s$~、CPU~数量~$P^s$~和内存大小~$M^s$~，链路的资源限制包括：带宽~$B^s$~、延迟~$D^s$~和延迟抖动~$J^s$~。表格\ref{tab:resource} 详细列举出了底层物理网络中的资源限制，并为各个资源限制定义权重影响因子以计算节点和链路的归一化资源限制。因此，底层物理网络中节点~$n^s$~的归一化资源~$c^s(n^s)$~可表示为:$$c^s(n^s)=S^s(n^s)\cdot w_S^n + I^s(n^s) \cdot w_I^n + P^s(n^s)\cdot w_P^n + M^s(n^s)\cdot w_M^n$$
\par
链路~$e^s$~的归一化资源~$b^s(e^s)$~可表示为: $$b^s(e^s)=B^s(e^s)\cdot w_B^e + D^s(e^s) \cdot w_D^e + J^s(e^s)\cdot w_J^e$$
\par
其中资源限制中的地理位置限制主要用于节点聚类分析，不用考虑在节点需求的归一化表示中。
\par
在虚拟网络请求和底层物理网络中，节点与链路的需求限制和资源限制都涉及影响因子的权重设定。根据不同的应用场景，可酌情调整各个影响因素的权重。譬如，在带宽主导的应用场景中，可酌情加大带宽影响因子的权重；在计算主导的应用场景中，可酌情加大~CPU~影响因子的权重等等。一般情况下，可简单地设定为均衡权重，即各个影响因子都是同等重要的。
\par
虚拟网络嵌入问题是动态的。随着时间推移，不同的虚拟网络请求会到达系统并接受嵌入映射处理，同时，系统中生命周期结束的虚拟网络请求会离开系统，并归还占用的资源。也就是说，当新的虚拟网络请求到达系统时，虚拟网络嵌入算法发挥作用，在条件允许的情况下，系统中的物理资源会被分配给虚拟网络请求；当虚拟网络请求的生命周期结束时，虚拟网络请求将离开系统，并释放占用的资源。因此，底层物理网络中的资源又分为可用资源~$c_{available}$~和占用资源~$c_{used}~$。我们定义虚拟网络请求及其占用的资源为一个映射集合~$M_{map}$~，映射集合中的任意一个映射对~$<r,c>\in M_{map}$~表示虚拟网络请求~$r$~占用了底层物理网络的~$c$~资源。
\par
在底层物理网络中，我们为每个区域的底层物理网络定义了一个位置中心，如第~$i$~个区域的底层物理网络~$G_i^s$~的位置中心为~$O_i^s$~，即~$O_i^s=(x_i,y_i)$~。位置中心是虚拟的，实际中并不真正存在这个中心点。我们将虚拟的位置中心~$O_i^s$~定义为该区域内所有节点的位置的几何中心：
$$O_i^s = \sum_{n^s\in N_i^s}\frac{l^s(n^s)}{|N_i^s|}$$
\par
其中，~$|N_i^s|$~表示第~$i$~个区域的底层物理网络中的节点个数。在实际生活中，每个区域的底层物理网络通常都是一个局域网环境，不同的区域底层物理网络通过~Internet~进行互联互通。由于~Internet~非常复杂，所以，我们假定在~Internet~中的带宽资源是无限的。虽然，上述假定是不成立的，但是我们对~Internet~的资源是没有办法控制的，因此上述假定也是合理的。

\subsection{节点聚类}
在面向媒体业务的虚拟网络嵌入算法（MSO-VNE）中，节点聚类分析是基于地理位置展开的，其原因有如下两点：
\par
1）底层区域性
\par
通常，数据中心或底层物理网络是分布在不同的地理位置的，具有明显的区域特性性。采用基于地理位置的节点聚类分析，可有效地利用底层物理网络的区域性特征，增加系统的信息量，提高准确率。
\par
2）~QoS~需求
\par
一般而言，虚拟网络请求都有地理位置的需求限制，尤其是实时业务的虚拟网络请求，对地理位置的需求限制更加迫切。因为它们需要更高的~QoS~服务质量以提高用户的体验质量，比如多媒体业务对带宽和延时的要求就比较苛刻，这是业务或服务本身的特质。为了保证这类业务或服务的~QoS~服务质量，通常把服务节点部署在离终端用户较近的地方，以减少延时，改善~QoS~服务质量。
\par
因此，采用基于地理位置的节点聚类分析，一方面，可以充分利用底层物理网络的区域性特征；另一方面，可以提高业务和服务的~QoS~服务质量。在虚拟网络请求~$G^v$~中，通过对虚拟节点应用基于地理位置的聚类分析，将请求中的节点归聚到若干个不同的类别，从而将原始的虚拟网络请求聚类为多个规模较小的子请求。虚拟网络请求中的任意节点~$n^v\in N^v$~，将被聚集到~$C(n^v)$~中：
$$C(n^v)=\mathop{argmin}_{i=0,1,2,\cdot,|O^s|-1}{dis(l^v(n^v),O_i^s)}$$
\par
每个虚拟节点~$n^v$~都被聚类到离它最近的区域底层物理网络~$G_i^s$~ 中，其中~$i=C(n^v)$~。同时，对于任意的虚拟网络请求~$G^v$~，其聚类后的子请求数量绝不超过区域底层物理网络的总数目~$|O^s|$~。聚类分析后，根据聚类结果，可以将虚拟网络请求~$G^v$~分割为一组虚拟网络子请求集合~$Q$~。该子请求集合中的任意一个子请求~$G_i^v\in Q$~ 都比原始的请求~$G^v$~规模小，同一个子请求~$G_i^v$~中的虚拟节点属于相同的聚类~$i$~，其中~$i$~也是第~$i$~个区域底层物理网络~$G_i^s$~ 的索引。由于我们假定不同的区域底层物理网络通过~Internet~互联互通，且~Internet~的链路资源是无限的。因此，任何端点在不同聚类中的虚拟链路都可以忽略不计。这样，每个虚拟网络子请求都可以独立地分配到区域底层物理网络~$G_i^s$~中进行局域嵌入处理。进而，所有的子请求都可以互不干扰地在不同的区域底层物理网络中进行并发的局域嵌入处理，这样一来，整个虚拟网络请求的嵌入性能便得到大幅度提升。
\subsection{动态服务均衡}
~PageRank~算法可以有效地评估~Web~页面的质量和受欢迎程度，每个页面的~rank value~排名值暗含了~Web~页面的重要性。通常，一个被很多高排名值网页链接的~Web~网页将获得一个较高的排名值，同时，一个页面链接到越多的页面，它对其他页面的排名值的贡献就越小。
\par
受~PageRank~思想的启发，我们在虚拟网络嵌入中引入了服务能力的概念，服务能力可用来评估特定节点的重要性。在通用网络模型~$G=(N,E)$~中，对于任意的节点~$n\in N$~，其服务能力~$r(n)$~可以定义为：
$$r(n)=\sum_{m\in N}{p(m,n)\cdot r(m)}$$
\par
在服务能力的定义中，我们引入了服务因子~$p(m,n)$~，它表示节点~$m$~对节点~$n$~的服务能力贡献，其定义如下：
$$p(m,n)=\left\{
\begin{array}{c l}
    f_1 & m=n\\
    \frac{f_2 \cdot r_0(n)}{\sum_{h \in N_{neigh}(m)}r_0(h)} &
    e(m,n)\in E\\
    0 & other
\end{array} \right.$$
\par
其中，~$N_{neigh}(m)$~表示节点~$m$~的邻居节点集合，而~$f_1$~和~$f_2$~是相应的权重常数，满足~$f_1 + f_2 = 1$~。~$r_0(n)$~是节点~$n$~的归一化资源，定义为节点资源和链接到该节点的链路资源的一半的乘积：
$$r_0(n)=c(n) \cdot \sum_{e \in E_{neigh}(n)}1/2\cdot b(e)$$
\par
其中，~$E_{neigh}(n)$~表示链接到节点~$n$~的链路集合，我们假定链路带宽是由链路两端的节点完全共享的，这就是系数1/2的来源。
\par
由此，动态服务均衡算法可以描述如表\ref{tab:dsba}所示。动态服务均衡算法中的迭代次数是多项式时间复杂度的。
\begin{table}[h]
\centering
\begin{tabular}{rl}
\hline
\multicolumn{2}{l}{$R=LB(G,\varepsilon_m)$，其中$G=(N,E)$，$\varepsilon_m$为阈值}\\\hline
1: & Compute each $r_0(n)$ and $p(m,n)$, initialize $i\gets 0$ \\
2: & while $\varepsilon < {\varepsilon}_m$ do \\
3: & \qquad $\varepsilon \gets 0$ \\
4: & \qquad for all $n \in N$ do \\
5: & \qquad \qquad $r_{i+1}(n) \gets \sum_{m\in N}p(m,n)\cdot r_i(m)$ \\
6: & \qquad \qquad $\varepsilon \gets \varepsilon + \|r_{i+1}(n)-r_i(n)\|$ \\
7: & \qquad \qquad $i \gets i + 1$ \\
8: & \qquad end for \\
9: & end while \\\hline
\end{tabular}
\caption{动态服务均衡算法}
\label{tab:dsba}
\end{table}

\par
动态服务均衡算法在虚拟网络嵌入中扮演着非常重要的角色。假设在底层物理网络中存在两个节点，它们可用的资源是完全相同的，然后，它们的邻居的可用资源，或者它们的邻居的邻居的可用资源却大不相同。此时，为了增加嵌入映射的成功概率，并减少虚拟链路在底层物理网络中的路径长度，我们宁愿选择其邻近节点具有更多资源的节点，也就是具有更高服务能力的节点。事实上，一个具有较高服务能力的底层节点至少满足以下两点中的任一点：
\par
1）节点自身有丰富的资源
\par
2）节点的邻居有丰富的资源
\par
这些原因让我们更加相信那些具有较高服务能力的底层节点，其成功嵌入的概率也会更高。同时，“能者多劳”的思想使得一个成功的嵌入有更好的负载均衡效果。同样地，我们认为高服务能力的虚拟节点具有优先嵌入权，因为当该节点嵌入失败的时候，它可以提前告知整个虚拟网络请求的失败。
\subsection{局部子请求映射}
如图\ref{fig:procedure}所示，每个虚拟网络子请求的嵌入映射是在局部嵌入阶段完成的。经过全局处理后，虚拟网络请求被聚类分割为多个规模较小的子请求，再经过简化处理后，各个子请求变得相互独立。因此，我们可以并发地处理多个子请求。在对子请求进行局部嵌入时，主要采用贪心策略。贪心策略以节点的动态服务能力为参考依据，优先将子请求中具有最大动态服务能力的虚拟节点映射到对应的区域底层物理网络中具有最大动态服务能力的底层节点上。局部嵌入的具体算法描述如表\ref{tab:local algo}所示。由此可知，所有虚拟网络子请求嵌入处理的时间复杂度为~$O(max_{0\leq i < |O^s|}(|N_i^v|^2 \cdot (|N_i^s|log|N_i^s| + |E_i^s|)))$~。
\begin{table}[h]
\centering
\begin{tabular}{r|p{0.9\textwidth}}
\hline
\multicolumn{2}{l}{局部嵌入算法：$LocalEmbed(G_i^s, G_i^v)$}\\\hline
 1.& 对~$G_i^s$~和~$G_i^v$~应用动态服务均衡分析，计算各节点的动态服务能力，时间复杂度为~$O(|N_i^s|log|N_i^s|)$~，其中~$O(|N_i^s|) > O(|N_i^v|)$~；\\\hline
2. & 从具有最高动态服务能力的虚拟节点~$n^v$~开始，依次处理所有未嵌入的虚拟节点，直到所有虚拟节点都被嵌入为止；\\\hline
2.1. & 从区域底层物理网络中选择最多~$k$~个最高动态服务能力的候选节点，这些候选节点都能满足节点~$n^v$~的需求限制。时间复杂度为~$O(N_i^s)$~； \\\hline
2.2. & 找出每个候选节点到已映射节点之间的最短路径，并计算总的路径开销，时间复杂度为~$O(|N_i^v|\cdot(|N_i^s|log|N_i^s|) + |E_i^s|)$~； \\\hline
2.3. & 在~$k$~个候选节点中，找出具有最小的总的路径开销的底层节点~$n^s$~，时间复杂度为~$O(k)$~； \\\hline
2.4. & 将虚拟节点~$n^v$~映射到底层节点~$n^s$~上，同时完成已映射节点到~$n^s$~节点之间的链路映射，时间复杂度为~$O(|E_{neigh}^v(n^v)|)$~； \\\hline
3. & 当所有的虚拟节点都成功映射后，分配实际的资源以提供服务，时间复杂度为~$O(|N_i^v| + |E_i^v|)$~；\\\hline
\end{tabular}
\caption{虚拟网络嵌入的局部嵌入算法}
\label{tab:local algo}
\end{table}

\section{仿真验证}
\subsection{仿真环境}
为了评估本章提出的面向媒体业务的虚拟网络嵌入算法，~MSO-VNE~，本节将详细介绍我们为该算法设计的仿真实验。在仿真实验中，我们设计并实现了离散事件模拟器，以更贴近现实的方式模拟虚拟网络请求的到来和被处理的过程。仿真实验可以有效地评估虚拟网络嵌入算法的性能，也为虚拟网络嵌入算法在工程中的实际应用提供依据和保障。
\par
在实际生活中，真实的底层物理网络基础设施的拓扑是很难获取的，同时，虚拟网络请求的拓扑也很难得到。因此，本节采用人工合成的网络拓扑，我们使用的合成工具是~GT-ITM (Georgia Tech Internetwork Topology Models)，~该拓扑生成器可以用来生成以平面随机图和层次图作为模型的网络拓扑。最简单的平面随机图模型是纯随机模型：结点在平面上随机分布，任意两个结点间有边的概率为~$a$~。纯随机模型非常简单，且不能很好地反映现实网络的拓扑结构，所以在此基础上又提出了几种平面随机图模型：
\par
1）~Waxman 1~模型\par
该模型中，从结点~$u$~到~$v$~有边的概率为~$P(u,v)=a*e^{-d/(bL)}$~，其中~$0<a,b\leq1$~，~$d$~是两结点间的距离，~$L=\sqrt{2}*scale$~是平面上任意两结点间的最大距离。~$a$~增大则图中边的数目会增大，~$b$~增大则图中长边数与短边数的比值会增大。\par
2）~Waxman 2~模型\par
该模型和~Waxman 1~模型很相似，将~Waxman 1~模型中的参数~$d$~的取值范围变为~$0$~到~$L$~之间的随机数即是~Waxman 2~模型。\par
3）~Doar-Leslie~模型\par
该模型和~Waxman 1~模型很相似，将~Waxman 1~模型中得到的概率值~$P(u,v)$~乘以一个比例因子~$ke/n$~便是~Doar-Leslie~模型。其中~$e$~ 是结点度数的期望值，~$n$~是结点数，~$k$~是由~$a$~，~$b$~共同决定的常数。\par
4）指数模型\par
在指数模型中，从结点~$u$~到~$v$~有边的概率为~$P(u,v)=a*e^{-d/(L-d)}$~，由此可知，节点间有边的概率随着节点间距离的增加而成指数级的降低。\par
5）~Locality~模型\par
在Locality模型中，根据两结点间的距离将结点对分成不同的等级，不同等级的结点对之间有边的概率不同。譬如在两级模型中的分级概率模型如下：\par
$$P(u,v)=\left\{
\begin{array}{c l}
    a, & d < L*radius\\
    b, & d \geq L*radius
\end{array}\right.$$
\par
也就是说，如果节点~$u$~和~$v$~之间的距离~$d$~满足~$d<L*radius$~，则节点~$u$~和~$v$~之间有边的概率为~$P(u,v)=a$~，否则节点间有边的概率为~$P(u,v)=b$~，其中~$radius$~ 用来确定分级界限。\par
平面随机图是层次图的基础，层次图一般由多个平面随机图组成，~GT-ITM~中的层次图主要包括两类：~N-Level~和~Transit-Stub~。其中~N-Level~采用递归的方式来生成网络拓扑图：首先用上述六种随机图模型中的任一种生成一个平面随机图，作为首层图；然后用平面随机图代替首层图中的每一个结点，并且依次替代下去。在~Transit-Stub~中，将结点划入不同类型的域，再将这些域连接起来：首先生成一个平面随机图，图中的每一个结点代表一个~transit~域；然后用平面随机图代替这些~transit~域，表示这些~transit~域的骨干拓扑；对~transit~域中的每个结点，生成一个或多个随机平面图作为~stub~域，并将其和结点连接起来；最后还可以在特定的结点对之间增加一些额外边，这些结点对需满足：一个在~transit~域一个在~stub~域，或者在不同的~stub~域。
\par
在仿真实验中，我们采用~Transit-Stub~模型构建底层物理网络拓扑，采用平面随机图模型合成虚拟网络请求。我们构建了~3~个区域底层物理网络和成千上万个虚拟网络请求。其中，每个区域底层物理网络包含~50~ 个节点，覆盖~$80\times80$~的网格区域。同时，我们假定不同的区域底层网络网络通过~Internet~互联互通，考虑到~Internet~ 的复杂性和不可控制性，我们假定~Internet~有无限的链路资源。为了使我们的仿真实验更接近真实情景，我们设定虚拟网络请求的到达服从泊松分布，平均到达速率是每~100~个时间单位~4~到~8~个请求不等。每个虚拟网络请求的生存周期服从平均时间为~1000~个时间单位的指数分布，且每个虚拟网络请求的节点数量是~2~到~10~的均匀分布。
\par
仿真实验的主要目的是评估面向媒体业务的虚拟网络嵌入算法~MSO-VNE~ 的性能，因此，实验参照对象是必不可少的。我们在仿真实验中选择的参照对象是现有的~D-ViNE~算法和~R-ViNE~算法，主要的评估指标包括时间复杂度、负载分布、平均收益开销比和平均接受率。为了更真实准确地评估~MSO-VNE~算法的性能，我们在相同的仿真环境下对同样的数据集应用以上三种不同的虚拟网络嵌入算法。
\subsection{性能评估}
\subsubsection{时间复杂度}
虚拟网络嵌入问题是典型的NP难问题，其时间复杂度非常高。因此，现有的研究大多倾向于设计启发式算法来解决。譬如，~D-ViNE~算法和~R-ViNE~算法就是典型的基于启发式的虚拟网络嵌入算法。我们先来详细分析~D-ViNE~算法的时间复杂度。
\par
~D-ViNE~算法是协调了节点映射和链路映射的虚拟网络嵌入算法，该算法首先会结合虚拟网络请求构建增强的底层物理网络拓扑，这一步骤的时间复杂度为~$O(|N^v|)$~。 然后，~D-ViNE~ 算法将着力解决整数线性规划问题，其时间复杂度为~$O((|E^s|(1+|E^v|))^{3.5}L^2lnLlnlnL)$~。最后，~D-ViNE~算法将以时间复杂度~$O((|E^s||E^v|)^{3.5}L^2lnLlnlnL)$~来解决链路映射相关的~MCF~问题。由此可知，在~D-ViNE~算法中，整数线性规划问题是其复杂度最高的部分，它也就是整个~D-ViNE~算法的时间复杂度。
\par
在面向媒体业务的虚拟网络映射算法~MSO-VNE~中，全局处理阶段将虚拟网络请求划分为多个规模较小的子请求，相比原始的虚拟网络请求，对规模较小的子请求进行嵌入处理具有更低的时间复杂度。同时，局域嵌入阶段可并发地嵌入多个子请求，便进一步降低了虚拟网络嵌入处理的时间复杂度。如表\ref{tab:local algo}所示，面向媒体业务的虚拟网络嵌入算法~MSO-VNE~的时间复杂度为：
$$O(\max_{0\leq i < |O^s|}(|N_i^v|^2 \cdot (|N_i^s|log|N_i^s| + |E_i^s|)))$$
\par
即使在最坏的情况下，当所有的区域底层物理网络都位于同一个地理位置时，虚拟网络嵌入算法的时间复杂度演变为：
$$O(|N^v|^2 \cdot (|N^s|log|N^s| + |E^s|))$$
\par
由于底层物理网络和虚拟网络请求都是连通图，满足~$O(|N|)<O(|E|)$~，因此，虚拟网络嵌入算法~MSO-VNE~的时间复杂度可简化为：
$$O(|E^v|^2 \cdot |E^s|log|E^s)$$
\par
与现有的~D-ViNE~算法相比，很显然，我们提出的~MSO-VNE~算法具有更低的时间复杂度。

\subsubsection{负载分布}
负载分布包括底层物理网络中物理节点上的负载分布和物理链路上的负载分布。负载分布主要衡量在一段时间内，底层物理网络中各个物理节点和链路上的负载情况，以及全部物理节点和链路上的负载分布情况。
\par
对于~SuperNova~服务虚拟化平台而言，虚拟网络请求就是底层物理网络的负载。具体而言，虚拟网络请求中的节点会根据其需求限制占用底层物理网络中节点的资源，如~CPU~资源、存储资源等；同时，虚拟网络请求中的链路也会根据其需求限制占用底层物理网络中链路的资源，如带宽资源等。由于嵌入算法和部署策略的不同，导致这些虚拟节点负载和虚拟链路负载在底层物理网络中的分布各不相同。因此，衡量负载分布的具体情况，可以窥见虚拟网络嵌入算法的性能。
\par
需要注意的是，虚拟网络嵌入问题是动态问题。随着时间的推移，新的虚拟网络请求会到达底层物理网络并占用底层物理网络资源，同时，过期的虚拟网络请求会随着其生命周期的结束会离开底层物理网络并释放其占用的资源。因此，底层物理网络中的资源使用情况是动态变化的。另外，由于我们假定虚拟网络请求的到达服从泊松分布，虚拟网络请求的生命周期服从指数分布。因此，底层物理网络中总体资源的使用情况在动态变化中能保持基本平稳，这可从仿真实验结果图~\ref{fig:nb}~和图~\ref{fig:eb}~中看出。
\par
仿真实验还可反映出虚拟网络嵌入算法的性能。从实验结果图中，我们可以看出，~MSO-VNE~算法具有更好的均衡负载分布能力。如图~\ref{fig:nb}~和图~\ref{fig:eb}~所示，在~MSO-VNE~算法中，底层物理资源使用得最多和最少的底层物理网络节点和链路的比例都要明显低于在其他两个算法。换句话说，在~D-ViNE~ 算法和~R-ViNE~算法中，存在更多的资源利用不合理的底层物理节点和链路，其利用不合理性在于：这些节点资源和链路的资源要么被过度使用，要么没有得到充分地利用。
\par
综上所述，面向媒体业务的虚拟网络嵌入算法~MSO-VNE~相比于~D-ViNE~ 算法和~R-ViNE~算法具有更好的负载均衡能力，~MSO-VNE~算法使得虚拟网络请求中的节点负载和链路负载在底层物理网络中的分布更均衡，从而提升了底层物理网络中的资源利用率。
\begin{figure}[h]
\includegraphics[width=\textwidth]{nb.eps}
\caption{底层物理网络中的节点负载分布}
\label{fig:nb}
\end{figure}

\begin{figure}[h]
\includegraphics[width=\textwidth]{eb.eps}
\caption{底层物理网络中的链路负载分布}
\label{fig:eb}
\end{figure}

\subsubsection{平均收益开销比}
在虚拟网络嵌入问题中，存在“收益”和“开销”两个概念。收益是指当成功嵌入一个虚拟网络请求后，底层物理网络因承载该虚拟网络请求获得的收益。开销是指当成功嵌入一个虚拟网络请求后，底层物理网络因承载该虚拟网络请求的资源开销。通常，对于节点而言，其收益和开销是相同的。譬如虚拟节点需要~50M~存储空间，为承载该虚拟节点，底层物理网络需要分配~50M~的存储空间给该虚拟节点，不管是从一个底层节点上分配~50M~存储空间，还是多个底层节点共同凑齐~50M~存储空间。底层物理网络的收益和开销都是~50M~的存储空间，因此，其收益和开销是相同的，收益开销比为~1~，是恒定不变的。\par
如图\ref{fig:rcr}所示，在三个算法中，MSO-VNE算法有最高的平均收益开销比，这就意味着MSO-VNE获得相同的收益只需要更少的开销。实际上，MSO-VNE较高的平均收益开销比来源于虚拟链路的较短的底层路径长度，进一步，这也是受益于动态服务均衡分析。

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{rcr.eps}
\caption{平均收益开销比对比结果}
\label{fig:rcr}
\end{figure}

\subsubsection{平均接受率}
平均接受率衡量的是已接受的请求在总请求中的比例，如图\ref{fig:accept}所示，在所有的算法中，MSO-VNE有最高的平均接受率。因此，在相同的环境下，MSO-VNE算法能接受的请求绝不会比其他的算法少。
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{accept.eps}
\caption{平均接受率对比结果}
\label{fig:accept}
\end{figure}
\par
\subsection{小结}
\section{面向媒体业务的资源映射交互框架}
基于面向媒体业务的虚拟网络嵌入算法~MSO-VNE，我们基于MSO-VNE 算法提出了面向媒体业务的资源映射交互框架。
\subsection{系统框架}
在面向媒体业务的资源映射交互框架中，MSO-VNE算法是核心模块。尽管虚拟网络嵌入问题起源于网络虚拟化，但它仍然属于资源管理领域，因此，我们将其应用到资源映射交互框架中，以处理资源映射问题。由于MSO-VNE 算法是面向媒体业务的，因此，将其应用到面向媒体业务的资源映射管理中，可以保证媒体服务的QoS服务质量需求。
\par
如图\ref{fig:framework}所示，资源映射交互框架主要包括以下几个模块：
\begin{itemize}
\item \textbf{用户接口模块}是交互框架中面向用户的部分，用户在该模块定义他们的需求并请求特定的服务；
\item \textbf{预处理模块}的职责是对用户的请求进行预处理，使得该请求不仅是人类可理解的，更是计算机可理解的；
\item \textbf{资源映射模块}是交互框架的核心，我们采用MSO-VNE算法来辅助处理资源映射；
\item \textbf{资源分配模块}是在当资源映射成功后，进行真正的资源分配；
\item \textbf{资源监控模块}的职责是监控资源池中的任何变化并进行同步管理。
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{framework.eps}
\caption{面向媒体业务的资源交互系统框架}
\label{fig:framework}
\end{figure}

从整体来看，面向媒体业务的资源映射交互框架可以看做两层：用户层和系统层。显然，用户层的设计是面向用户的，用户通过定义他们的需求并发起请求，接着需求会被分析和处理。当然，任何请求的具体的分析和处理都是在系统层得到处理的，而系统层对用户是透明的。用户层的设计宗旨是让用户专注在他们所关心的服务而不是任何其他的琐碎细节，譬如怎样预处理，如何执行映射抑或如何分配或监控资源。这些琐碎的细节都是有系统层来处理的。
\par
通常，当用户的请求到达时，系统层开始工作。首先，系统层执行预处理以提取有用的信息并分析用户的需求。系统层的核心是资源映射，在资源映射中，我们采用了MSO-VNE算法以执行映射匹配。我们从资源监控模块获取系统可用的资源，如果有足够的资源，用户的请求就会得到成功的匹配。当成功匹配后，资源分配子模块会为用户分配实际的资源。当然，不管是否能够成功映射，系统层都会将处理结果反馈给用户层。反馈对系统是有用的，不仅可以告诉用户请求的处理请求，也可以辅助用户做更好的决策。
\par
下面，我们将详细描述交互系统中的各个模块设计。
\subsection{用户界面}
用户界面是面向用户的，其战略目标是简化用户操作，提升用户体验。
用户界面模块的设计主要考虑以下几个子模块：
\begin{itemize}
\item 功能定义
\par 功能定义模块主要考虑并定义系统可能提供的功能，很显然，功能定义部分和具体的应用场景密切相关。一个良好的功能定义模块可以清晰地将系统呈现在用户面前，很好地回答“系统是什么”以及“系统能做什么”等类似的问题，留给用户良好的印象。
\item 交互设计
\par
交互设计主要解决用户该如何和系统通信、如何交流等问题。常见的交互方式包括命令行、客户端工具、Web网页交互等。不管如何，人们越来越倾向并习惯于可视化交互。
\item 反馈设计
\par
广义上来说，反馈设计也可以算做是交互设计的一个部分，即是系统将最终的处理结果反馈给用户，以便用户做进一步的决策等。
\item 页面布局
\par
页面布局简单来说就是系统元素的呈现方式，如何将系统功能、交互等合理地组合布局，如何突出系统的重点，如何吸引用户的注意力等。
\end{itemize}

\subsection{预处理}
预处理是在进行资源映射前，对用户的请求进行适当的整理和预处理。预处理主要的子模块如下：
\begin{itemize}
\item 信息抽取
\par
从用户提交的请求中抽取系统需要的有用的信息，剔除冗余的信息，以减小处理复杂度并提高效率。
\item 需求解析
\par
需求解析包括需求分类以及信息呈现方式等基本预处理，如统一格式化信息。
\end{itemize}

\subsection{资源映射}
资源映射模块主要包括以下子模块：
\begin{itemize}
\item 资源获取
\par
从资源监控模块获取系统的资源使用情况，主要关注系统的可用资源。
\item 映射匹配
\par
映射匹配是将用户的请求和系统的可用资源进行匹配计算。我们采用的是MSO-VNE算法进行映射匹配。
\end{itemize}

\subsection{资源监控}
资源监控模块主要包括以下子模块：
\begin{itemize}
\item 监控
\item 同步管理
\end{itemize}
顾名思义，监控模块就是监控资源池中资源的变化，并进行同步和更新管理。
\subsection{资源分配}
资源分配模块主要包括以下子模块：
\begin{itemize}
\item 分配
\item 同步管理
\end{itemize}
资源分配模块的功能很直接明确：当映射成功的时候，为用户的请求分配真正的资源为其提供服务。并保持资源池中资源的同步和更新操作。

\section{小结}
本章提出了面向媒体业务的虚拟网络嵌入算法MSO-VNE，并详细阐述了算法的实现细节。MSO-VNE算法根据虚拟网络请求和底层物理网络的地理位置特征，应用节点聚类，充分利用了分而治之策略和并发处理策略的优势。同时，本章在MSO-VNE算法中应用了动态服务均衡分析，以获得较好的动态服务均衡性能。
\par
虽然，VNE问题起源于网络虚拟化，但它仍是资源管理问题。因此，本章提出了面向媒体业务的资源映射交互框架，在交互框架中采用了MSO-VNE算法作为其资源映射核心部件。
\par
为了评估MSO-VNE算法的性能，我们设计了仿真实验。仿真结果表明MSO-VNE算法具有很好的性能，包括较低的时间复杂度、更好的负载均衡、更高的收益开销比和更高的平均接受率。这些良好的性能进一步给我们更大的信心，使我们更加相信基于MSO-VNE的交互框架可以获得更好的QoS服务质量和更好的用户体验。

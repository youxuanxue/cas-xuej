\chapter{面向媒体业务的虚拟网络嵌入研究}
\label{chap:vne}
\section{引言}
随着云端应用服务和海量数据需求的日益增加，传统网络僵化的结构难以满足新兴业务的需求。网络虚拟化被认为是未来网络的关键技术。网络虚拟化技术可克服传统网络的僵化问题，允许多个异构的虚拟网络在一个共享的底层物理网络上共存。类似于服务器虚拟化技术让多个服务器实例宿住同一台物理主机上，网络虚拟化允许多个异构的虚拟网络架构在同一个共享的物理网络上。各个虚拟网络的运作是相互独立和透明的，就好像只有这一个虚拟网络在物理网络上运行一样。
\par
~VNE, Virtual Network Embedding~，即虚拟网络嵌入，是网络虚拟化必须要解决的关键问题。虚拟网络嵌入通过在共享的物理网络上实例化虚拟网络，有效地将虚拟网络请求拓扑中的虚拟节点和虚拟链接嵌入映射到底层物理网络上，最大化从底层物理网络中获得的收益，获取最佳的动态资源分配，为最终用户提供定制的端到端保证的服务。虚拟网络嵌入问题是NP难问题，其时间复杂度非常高，所以，现有的研究大多都侧重于设计基于启发式的算法来解决。
\par
本章针对媒体业务的~QoS~需求特征，结合底层物理网络和虚拟网络请求的地理位置分布属性，提出了面向媒体业务的虚拟网络嵌入算法，~MSO-VNE~。基于~MSO-VNE~算法，本章设计并提出了面向媒体业务的资源映射交互框架。
\par
本章的内容安排如下：\ref{sec:vne-relate}节介绍了虚拟网络嵌入的相关的研究工作和研究进展；\ref{sec:vne-suanfa}节详细阐述了面向媒体业务的虚拟网络嵌入算法的设计思想和技术细节；\ref{sec:vne-fangzhen} 节对~MSO-VNE~算法进行仿真验证以评估该算法的性能；
\ref{sec:vne-kuangjia}节详细描述了基于~MSO-VNE~算法的面向媒体业务的资源映射交互框架的整体架构和各个组件模块的详细设计；最后， \ref{sec:vne-xiaojie}节对本章的内容进行总结。
\section{相关研究}
\label{sec:vne-relate}
虚拟网络嵌入问题要解决的问题是在底层物理网络中搜寻合适的拓扑承载虚拟网络请求，因此，虚拟网络嵌入问题可分为两个子问题：虚拟节点映射问题和虚拟链接映射问题。虚拟节点映射，即将虚拟节点嵌入映射到底层物理节点上，由物理节点为虚拟节点提供必要的物理资源。虚拟链路映射，即将连接虚拟节点的虚拟链路嵌入映射到底层物理网络中连接对应节点的路径上。
\par
~Multi-way separator problem\cite{multi-way}~是典型的~NP~难问题，而虚拟网络嵌入~VNE~问题与~multi-way separator problem~密切相关，因此，虚拟网络嵌入~VNE~问题也是典型的~NP~难问题。在虚拟网络嵌入问题中，即使是所有的虚拟节点都被成功映射后，虚拟链路的映射会退化为不可分流问题\cite{unsplittable1,unsplittable2}，这仍然是~NP~难问题。因此，现有的研究大多都致力于设计基于启发式的算法来解决~VNE~问题。譬如，文献\cite{uncoordinate}提出了一种路径可分离和可移植的虚拟网络嵌入架构，在该架构中，虚拟网络嵌入问题的处理过程被分为两个独立的阶段：节点映射阶段和链路映射阶段。通过组合不同的节点映射算法和链路映射算法，该架构可生成不同的虚拟网络映射算法，针对不同的应用场景，可选择不同的算法对虚拟网络请求进行嵌入映射处理。相反，文献\cite{augmentation}通过联合节点映射和链路映射，提出了协作式的虚拟网络嵌入算法。该算法首先在底层物理网络上构建基于虚拟网络请求的增强图，充分考虑节点和链路的资源属性并在增强图中解决虚拟网络嵌入问题。除此之外，文献\cite{matrix}从问题建模入手，通过反思网络模型，将虚拟网络请求和底层物理网络建模为流量矩阵而不是通用的内部拓扑，以独特的方式解决~VNE~问题。另外，许多新兴的思想和算法也被提出来解决虚拟网络嵌入问题，譬如，文献\cite{opportunity} 提出了基于机会主义资源共享的虚拟网络嵌入算法；文献\cite{svrvivable} 提出了可存活的虚拟网络嵌入算法。
\par
随着网络虚拟化技术的发展，许多成熟的虚拟网络嵌入算法被提出来，文献\cite{vne-survey}对近几年提出的虚拟网络嵌入算法进行深入调研和综合分析，提出了一种虚拟网络嵌入的分类学。该分类学认为目前的虚拟网络嵌入算法大致可以从以下几个方面进行分类：\par
\textbf{1、静态的~vs~动态的}\par
根据是否要变更或迁移虚拟网络请求，以及是否要扩展底层物理网络或重新进行资源分配，可以将虚拟网络嵌入~VNE~方法分为静态的和动态的。静态的~VNE~方法假定底层物理网络和虚拟网络请求都是静态不变的。相反，动态的~VNE~方法充分考虑到实际情况中虚拟网络请求可能发生的需求变更以及底层物理网络基础设施可能发生的扩展变化，在进行嵌入时会对部分虚拟网络请求进行必要的迁移，以及将底层物理网络资源进行必要的重新分配。通常，静态的虚拟网络嵌入是理想的情况，实际工程应用中的虚拟网络嵌入都是动态的。
\par
静态的~VNE~方法假定一切都是事先已知且不变的，但实际情况却远非如此，不管是虚拟网络请求还是底层物理网络，都可能存在变更，具体表现在以下几个方面：
\par
1）用户需求变更。这是用户主动提出的变更，尤其是在已嵌入的虚拟网络请求生命周期到期之前。
\par
2）供应商设施扩展。这类变更是底层物理网络基础设施提供商提出的变更，通常发生在业务壮大时需要补充扩展基础设施的情况。
\par
3）底层物理网络的碎片资源。与内存碎片一样，底层物理网络也会产生各种碎片资源。随着时间的推移，新的虚拟网络请求到达并嵌入，同时，过期的虚拟网络请求逐渐离开并释放资源。这些不断的加入与退出，使得底层物理网络的资源变得支离破碎，底层物理网络中大量的碎片资源将严重影响系统进一步接受新的虚拟网络请求，导致虚拟网络请求接受率下降；
\par
显然，这些变更和不确定性是静态~VNE~方法无法解决的，动态~VNE~方法会根据实际需求试图重新配置已映射的虚拟网络请求，重组资源的分配，优化底层物理网络的资源利用。虚拟网络重配置算法，~VNRe\cite{VNRe}~，是一种反应式和迭代式的动态~VNE~算法。该算法基于这样一个事实：大多数虚拟网络请求被拒绝都是由于底层物理链路的瓶颈。因此，当虚拟网络请求被拒绝的时候，对已映射的虚拟网络节点按照可迁移性进行排序，优先迁移最容易迁移的节点并重新映射被拒绝的虚拟网络请求。“迁移-嵌入”过程被迭代地进行，直到该虚拟网络请求成功映射或者达到一定的迭代次数。为了减少底层物理网络中的碎片资源并合理利用，可以采用周期性的重新配置算法\cite{periodic}。为了应对用户对虚拟网络请求的需求变更可采取资源重配置算法\cite{vnchange1,vnchange2}。在底层物理网络进行进化和扩展时，可以针对变更的底层物理网络进行相关的重新配置\cite{snchange}。总体而言，动态~VNE~算法可以根据不同的实际情况制定不同的迁移策略，包括针对链路瓶颈的迁移\cite{VNRe}，服务访问位置变化的迁移\cite{poschange} 等。另外，动态~VNE~算法可以追求不同的重新嵌入部署目标，如节省底层物理网络资源的重新配置\cite{snsave}。显然，动态~VNE~会有更好的映射效果，譬如更高的接受率，更少的底层物理网络资源开销和更好的资源利用率，但是动态~VNE~意味着迁移和重映射，其必然带来更大的计算开销，目前一些算法也在研究怎样减少动态~VNE~算法的计算开销\cite{costsave,periodic}。
\par
\textbf{2、分布式的~vs~中心式的}\par
在中心式的虚拟网络嵌入~VNE~方法中，由一个中心映射实体负责执行虚拟网络请求的嵌入操作。该中心映射实体在嵌入映射过程中，熟知整个系统的资源情况，包括网络系统中各个节点的资源使用情况和相应的链路资源使用情况。这些全局的知识和信息将有助于更加优化的嵌入，然而，中心式的嵌入映射的缺陷就是中心映射实体的单点失效性。如果中心映射实体出现故障或失败将导致整个系统中的虚拟网络映射失败。此外，在大型网络中可能有可伸缩性问题，单一的中心映射实体可能面对众多的虚拟网络请求而不知所措，从而严重影响虚拟网络嵌入的效率。
\par
与中心式的虚拟网络映射不同，在分布式的虚拟网络嵌入~VNE~方法中，由多个映射实体共同负责虚拟网络的嵌入，其优势在于它更高的嵌入效率和可伸缩性。分布式的虚拟网络嵌入通过将虚拟网络请求负载分散到多个映射实体，使得每个映射实体都能更好地应对嵌入，并提高虚拟网络嵌入的效率。然而，分布式的嵌入映射面临的问题是其增长的同步开销，多个映射实体需要汇总各自的嵌入映射结果并进行同步更新。另外，为了得到更优化的嵌入，每个映射实体希望获取到关于全局的足够多的系统信息，可用的信息越多，嵌入的效果就越好。但是，如果多个映射实体都留有足够多的系统全局信息，必然导致开销增大。因此， 需要在开销和嵌入性能之间进行平衡和折衷。
\par
目前，大多数虚拟网络嵌入~VNE~方法都是中心式的，而分布式的~VNE~一般指的是在不同底层物理网络设施提供商之间的分布式嵌入\cite{interinp1,interinp2,interinp3,interinp4}。
\par
\textbf{3、简洁的~vs~冗余的}\par
在简洁的虚拟网络嵌入~VNE~方法中，只使用必要的底层物理网络资源来承载虚拟网络请求，绝对不会预留额外的冗余资源。因此，可以使用相同的底层物理网络资源去映射嵌入更多的虚拟网络请求，最大化底层物理网络的收益并提高虚拟网络请求的接受率。然而，由于没有任何预留的冗余资源，使得当一些底层物理网络设备失败的时候，不能快速地从错误中恢复，使得系统的稳定性和可用性降低。
\par
相反，冗余的虚拟网络嵌入~VNE~方法在进行嵌入映射时，不仅为虚拟网络请求配备了必要的资源，还分配了额外的冗余资源。在这种情况下， 即使部分底层物理网络设备失效或在运行时失败时，都可迅速激活备份冗余资源并快速恢复使用。因此，冗余的~VNE~方法可以显著提高嵌入映射的可靠性，这种嵌入映射的可靠性是通过牺牲嵌入映射成本而获得的。嵌入可靠性和嵌入成本开销之间存在着平衡折衷：可靠性越高，嵌入成本越高，更多的资源被使用，可嵌入的虚拟网络请求就更少。
\par
综上所述，冗余的~VNE~方法比简洁的~VNE~方法更复杂，需要考虑更多的影响因素，包括预留多少冗余资源，当失败的时候如何启动后备资源等。
文献\cite{redundant1}充分考虑了业务请求的多样性和后备路径的重要性，在进行虚拟网络嵌入映射时，充分挖掘底层物理网络拓扑的信息并寻找有效的后备路径。文献\cite{Qosmap1,Qosmap2,Qosmap3}在进行虚拟网络嵌入时，不仅在映射的节点间搜寻直接的路径以满足虚拟网络请求的需求限制，还通过构造逐跳路径作为后备路径供虚拟网络请求选择。
\par
\textbf{4、协作的~vs~非协作的}\par
从虚拟网络的嵌入过程来看，可以分为两种嵌入方式：\par
\textbf{1）非协作的}\par
非协作的虚拟网络嵌入~VNE~方法将虚拟网络请求的嵌入映射分为两个独立的阶段：~VnoM~虚拟节点映射阶段和~VliM~虚拟链路映射阶段。该类~VNE~方法认为虚拟节点映射和虚拟链路映射是独立的和互不影响的，因此，该类~VNE~方法首先进行~VnoM~虚拟节点映射，~VNoM~一般遵循贪心算法：对于每个虚拟节点，选择节点资源最丰富的底层物理网络节点来承载该虚拟节点。然后，进行~VliM~虚拟链路映射，在虚拟节点映射到的物理节点之间寻找满足资源限制的底层物理链路或路径。~VliM~一般可采用单路径映射\cite{singleroute}，如~k~路最短路径\cite{kroute}，也可采用多路径映射\cite{multiroute}，如多商品流MCF等方法解决。
\par
\textbf{2）协作的}\par
协作的虚拟网络嵌入~VNE~方法通过协调节点映射和链路映射来进行虚拟网络请求的嵌入，有效地降低由于缺乏协调导致的链路开销，从而提高虚拟网络嵌入接受率，并改善长期收益。协作的~VNE~方法又可以分为两阶段的协作~VNE~方法和一阶段的协作~VNE~方法。
\par
两阶段的协作算法~D-ViNE~和~R-ViNE~\cite{dvine-rvine}，通过结合虚拟网络请求在底层物理网络创建增强图，即以虚拟节点为原型在底层物理网络中添加元节点。在增强图中，再对虚拟网络嵌入问题进行建模，并完成两个阶段的映射：~VnoM~虚拟节点映射和~VliM~虚拟链路映射。
\par
一阶段的协作映射是指虚拟链路和虚拟节点的映射是同时进行的。当第一个虚拟节点对映射成功时，紧接着对它们之间的虚拟链路进行映射。随着每个虚拟节点的成功映射，连接虚拟节点的虚拟链路也被成功映射。文献\cite{onestage}是典型的一阶段映射的~VNE~方法，通过~BFS，breadth-first search~ 算法计算节点在网络拓扑中的重要性，并依次映射每个节点和每条链路。

\section{面向媒体业务的虚拟网络嵌入算法设计}
\label{sec:vne-suanfa}
\subsection{整体架构}
本章提出了面向媒体业务的虚拟网络嵌入算法，~MSO-VNE~。该算法的整体架构如图\ref{fig:procedure}所示。~MSO-VNE~算法在进行虚拟网络嵌入时，主要分为以下两个阶段:
\par
\textbf{1）全局处理}
\par
在全局处理阶段，采用“中心式”的架构，对原始的虚拟网络请求运用节点聚类分析和分割处理，将原始的虚拟网络子请求划分为多个子请求。接着，每个子请求会被分派到相应区域的底层物理网络中进行局部嵌入。相比原始的虚拟网络请求，新的子请求具有更少的节点和更简单的链路，因此，各个子请求的嵌入处理过程会被大大简化，映射效率也会被大大提升。
\par
\textbf{2）局部嵌入}
\par
局部嵌入阶段是真正的嵌入和映射处理阶段，它的处理对象是全局处理阶段分割而成的所有子请求。由于子请求相比原始的请求有更小的规模，因此，局部嵌入计算的复杂度将大大减小。在这个阶段，多个子请求可以“分布式”地在各自区域的底层物理网络中执行真正的嵌入处理，进一步提高了嵌入效率。另外，在局部嵌入中，我们采用了动态服务均衡分析以辅助嵌入，提高了底层物理网络的资源利用率。
\par
在下面的章节中，我们将详细介绍面向媒体业务的虚拟网络嵌入算法~MSO-VNE~。
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{procedure.eps}
\caption{面向媒体业务的虚拟网络嵌入算法整体架构}
\label{fig:procedure}
\end{figure}

\subsection{网络模型}
\textbf{1）虚拟网络请求}
\par
虚拟网络请求可建模为带权重的无向图~$G^v=(N^v,E^v)$~，其中~$N^v$~是虚拟节点集合，而~$E^v$~是虚拟链路集合。定义虚拟节点~$n^v$~的邻居节点集合为~$N^v(n^v)$~，定义连接到节点~$n^v$~的链路集合为~$E^v(n^v)$~。虚拟网络请求中的虚拟节点和虚拟链路都与他们的需求限制相关联。我们定义虚拟网络请求中，虚拟节点的需求限制信息包括：地理位置~$L^v$~、存储容量~$S^v$~、磁盘~I/O~速率~$I^v$~、CPU~数量~$P^v$~和内存大小~$M^v$~，虚拟链路的需求限制包括：带宽~$B^v$~、 延迟~$D^v$~和延迟抖动~$J^v$~。表格\ref{tab:constraint}详细列举出了虚拟网络请求需求限制，并为各个需求限制定义权重影响因子以计算虚拟节点和虚拟链路的归一化需求限制。因此，虚拟网络请求中虚拟节点~$n^v$~的归一化资源~$c^v(n^v)$~可表示为: $$c^v(n^v)=S^v(n^v)\cdot w_S^n + I^v(n^v) \cdot w_I^n + P^v(n^v)\cdot w_P^n + M^v(n^v)\cdot w_M^n$$
\par
虚拟链路~$e^v$~的归一化资源~$b^v(e^v)$~可表示为:
$$b^v(e^v)=B^v(e^v)\cdot w_B^e + D^v(e^v) \cdot w_D^e + J^v(e^v)\cdot w_J^e$$
\par
其中需求限制中的地理位置限制主要用于节点聚类分析，不用考虑在节点需求的归一化表示中。

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{虚拟节点需求限制} & \multicolumn{3}{|c|}{虚拟链路需求限制}\\\hline
因素 & 符号表示 & 权重因子 & 因素 & 符号表示 & 权重因子\\\hline
地理位置 & $L^v$ &         & 带宽 &  $B^v$   & $w_B^e$ \\\hline
存储容量 & $S^v$ & $w_S^n$ & 延迟 &  $D^v$   & $w_D^e$ \\\hline
磁盘~I/O & $I^v$  & $w_I^n$ & 延迟抖动 & $J^v$ & $w_J^e$ \\\hline
CPU~数量 & $P^v$  & $w_P^n$ &           &       &      \\\hline
内存大小 & $M^v$ & $w_M^n$ &            &       &     \\\hline
归一化资源 & $c^v$ &       & 归一化资源& $b^v$ &       \\\hline
\multicolumn{3}{|c|}{$w_S^n + w_I^n + w_P^n + w_M^n = 1$} & \multicolumn{3}{|c|}{$w_B^e + w_D^e + w_J^e = 1$}\\\hline
\end{tabular}
\caption{虚拟网络请求的需求限制}
\label{tab:constraint}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{节点资源限制} & \multicolumn{3}{|c|}{链路资源限制}\\\hline
因素 & 符号表示 & 权重因子 & 因素 & 符号表示 & 权重因子\\\hline
地理位置 & $L^s$ &         & 带宽 &  $B^s$   & $w_B^e$ \\\hline
存储容量 & $S^s$ & $w_S^n$ & 延迟 &  $D^s$   & $w_D^e$ \\\hline
磁盘~I/O & $I^s$  & $w_I^n$ & 延迟抖动 & $J^s$ & $w_J^e$ \\\hline
CPU~数量 & $P^s$  & $w_P^n$ &           &       &      \\\hline
内存大小 & $M^s$ & $w_M^n$ &            &       &     \\\hline
归一化资源 & $c^s$ &       & 归一化资源& $b^s$ &       \\\hline
\multicolumn{3}{|c|}{$w_S^n + w_I^n + w_P^n + w_M^n = 1$} & \multicolumn{3}{|c|}{$w_B^e + w_D^e + w_J^e = 1$}\\\hline
\end{tabular}
\caption{底层物理网络的资源限制}
\label{tab:resource}
\end{table}

\par
\textbf{2）底层物理网络}
\par
同样地，底层物理网络可建模为带权重的无向图~$G^s=(N^s,E^s)$~，底层物理网络的第~$i$~个区域可表示为无向图~$G_i^s=(N_i^s,E_i^s)$~，其中~$N_i^s$~表示区域~$i$~内的节点集合，而~$E_i^s$~表示区域~$i$~ 内的链路集合。定义节点~$n^s$~的邻居节点集合为~$N^s(n^s)$~，定义连接到节点~$n^s$~的链路集合为~$E^s(n^s)$~。底层物理网络中的节点和链路都与他们的资源限制相关联。在底层物理网络中，我们定义节点的资源限制信息包括：地理的位置~$L^s$~、 存储容量~$S^s$~、 磁盘~I/O~ 速率~$I^s$~、CPU~数量~$P^s$~和内存大小~$M^s$~，链路的资源限制包括：带宽~$B^s$~、延迟~$D^s$~和延迟抖动~$J^s$~。表格\ref{tab:resource} 详细列举出了底层物理网络中的资源限制，并为各个资源限制定义权重影响因子以计算节点和链路的归一化资源限制。因此，底层物理网络中节点~$n^s$~的归一化资源~$c^s(n^s)$~可表示为:$$c^s(n^s)=S^s(n^s)\cdot w_S^n + I^s(n^s) \cdot w_I^n + P^s(n^s)\cdot w_P^n + M^s(n^s)\cdot w_M^n$$
\par
链路~$e^s$~的归一化资源~$b^s(e^s)$~可表示为: $$b^s(e^s)=B^s(e^s)\cdot w_B^e + D^s(e^s) \cdot w_D^e + J^s(e^s)\cdot w_J^e$$
\par
其中资源限制中的地理位置限制主要用于节点聚类分析，不用考虑在节点需求的归一化表示中。
\par
在虚拟网络请求和底层物理网络中，节点与链路的需求限制和资源限制都涉及影响因子的权重设定。根据不同的应用场景，可酌情调整各个影响因素的权重。譬如，在带宽主导的应用场景中，可酌情加大带宽影响因子的权重；在计算主导的应用场景中，可酌情加大~CPU~影响因子的权重等等。一般情况下，可简单地设定为均衡权重，即各个影响因子都是同等重要的。
\par
虚拟网络嵌入问题是动态的。随着时间推移，不同的虚拟网络请求会到达系统并接受嵌入映射处理，同时，系统中生命周期结束的虚拟网络请求会离开系统，并归还占用的资源。也就是说，当新的虚拟网络请求到达系统时，虚拟网络嵌入算法发挥作用，在条件允许的情况下，系统中的物理资源会被分配给虚拟网络请求；当虚拟网络请求的生命周期结束时，虚拟网络请求将离开系统，并释放占用的资源。因此，底层物理网络中的资源又分为可用资源~$c_{available}$~和占用资源~$c_{used}~$。我们定义虚拟网络请求及其占用的资源为一个映射集合~$M_{map}$~，映射集合中的任意一个映射对~$<r,c>\in M_{map}$~表示虚拟网络请求~$r$~占用了底层物理网络的~$c$~资源。
\par
在底层物理网络中，我们为每个区域的底层物理网络定义了一个位置中心，如第~$i$~个区域的底层物理网络~$G_i^s$~的位置中心为~$O_i^s$~，即~$O_i^s=(x_i,y_i)$~。位置中心是虚拟的，实际中并不真正存在这个中心点。我们将虚拟的位置中心~$O_i^s$~定义为该区域内所有节点的位置的几何中心：
$$O_i^s = \sum_{n^s\in N_i^s}\frac{l^s(n^s)}{|N_i^s|}$$
\par
其中，~$|N_i^s|$~表示第~$i$~个区域的底层物理网络中的节点个数。在实际生活中，每个区域的底层物理网络通常都是一个局域网环境，不同的区域底层物理网络通过~Internet~进行互联互通。由于~Internet~非常复杂，所以，我们假定在~Internet~中的带宽资源是无限的。虽然，上述假定是不成立的，但是我们对~Internet~的资源是没有办法控制的，因此上述假定也是合理的。

\subsection{节点聚类}
在面向媒体业务的虚拟网络嵌入算法（MSO-VNE）中，节点聚类分析是基于地理位置展开的，其原因有如下两点：
\par
1）底层区域性
\par
通常，数据中心或底层物理网络是分布在不同的地理位置的，具有明显的区域特性性。采用基于地理位置的节点聚类分析，可有效地利用底层物理网络的区域性特征，增加系统的信息量，提高准确率。
\par
2）~QoS~需求
\par
一般而言，虚拟网络请求都有地理位置的需求限制，尤其是实时业务的虚拟网络请求，对地理位置的需求限制更加迫切。因为它们需要更高的~QoS~服务质量以提高用户的体验质量，比如多媒体业务对带宽和延时的要求就比较苛刻，这是业务或服务本身的特质。为了保证这类业务或服务的~QoS~服务质量，通常把服务节点部署在离终端用户较近的地方，以减少延时，改善~QoS~服务质量。
\par
因此，采用基于地理位置的节点聚类分析，一方面，可以充分利用底层物理网络的区域性特征；另一方面，可以提高业务和服务的~QoS~服务质量。在虚拟网络请求~$G^v$~中，通过对虚拟节点应用基于地理位置的聚类分析，将请求中的节点归聚到若干个不同的类别，从而将原始的虚拟网络请求聚类为多个规模较小的子请求。虚拟网络请求中的任意节点~$n^v\in N^v$~，将被聚集到~$C(n^v)$~中：
$$C(n^v)=\mathop{argmin}_{i=0,1,2,\cdot,|O^s|-1}{dis(l^v(n^v),O_i^s)}$$
\par
每个虚拟节点~$n^v$~都被聚类到离它最近的区域底层物理网络~$G_i^s$~ 中，其中~$i=C(n^v)$~。同时，对于任意的虚拟网络请求~$G^v$~，其聚类后的子请求数量绝不超过区域底层物理网络的总数目~$|O^s|$~。聚类分析后，根据聚类结果，可以将虚拟网络请求~$G^v$~分割为一组虚拟网络子请求集合~$Q$~。该子请求集合中的任意一个子请求~$G_i^v\in Q$~ 都比原始的请求~$G^v$~规模小，同一个子请求~$G_i^v$~中的虚拟节点属于相同的聚类~$i$~，其中~$i$~也是第~$i$~个区域底层物理网络~$G_i^s$~ 的索引。由于我们假定不同的区域底层物理网络通过~Internet~互联互通，且~Internet~的链路资源是无限的。因此，任何端点在不同聚类中的虚拟链路都可以忽略不计。这样，每个虚拟网络子请求都可以独立地分配到区域底层物理网络~$G_i^s$~中进行局域嵌入处理。进而，所有的子请求都可以互不干扰地在不同的区域底层物理网络中进行并发的局域嵌入处理，这样一来，整个虚拟网络请求的嵌入性能便得到大幅度提升。
\subsection{动态服务均衡}
~PageRank~算法可以有效地评估~Web~页面的质量和受欢迎程度，每个页面的~rank value~排名值暗含了~Web~页面的重要性。通常，一个被很多高排名值网页链接的~Web~网页将获得一个较高的排名值，同时，一个页面链接到越多的页面，它对其他页面的排名值的贡献就越小。
\par
受~PageRank~思想的启发，我们在虚拟网络嵌入中引入了服务能力的概念，服务能力可用来评估特定节点的重要性。在通用网络模型~$G=(N,E)$~中，对于任意的节点~$n\in N$~，其服务能力~$r(n)$~可以定义为：
$$r(n)=\sum_{m\in N}{p(m,n)\cdot r(m)}$$
\par
在服务能力的定义中，我们引入了服务因子~$p(m,n)$~，它表示节点~$m$~对节点~$n$~的服务能力贡献，其定义如下：
$$p(m,n)=\left\{
\begin{array}{c l}
    f_1 & m=n\\
    \frac{f_2 \cdot r_0(n)}{\sum_{h \in N_{neigh}(m)}r_0(h)} &
    e(m,n)\in E\\
    0 & other
\end{array} \right.$$
\par
其中，~$N_{neigh}(m)$~表示节点~$m$~的邻居节点集合，而~$f_1$~和~$f_2$~是相应的权重常数，满足~$f_1 + f_2 = 1$~。~$r_0(n)$~是节点~$n$~的归一化资源，定义为节点资源和链接到该节点的链路资源的一半的乘积：
$$r_0(n)=c(n) \cdot \sum_{e \in E_{neigh}(n)}1/2\cdot b(e)$$
\par
其中，~$E_{neigh}(n)$~表示链接到节点~$n$~的链路集合，我们假定链路带宽是由链路两端的节点完全共享的，这就是系数1/2的来源。
\par
由此，动态服务均衡算法可以描述如表\ref{tab:dsba}所示。动态服务均衡算法中的迭代次数是多项式时间复杂度的。
\begin{table}[h]
\centering
\begin{tabular}{rl}
\hline
\multicolumn{2}{l}{$R=LB(G,\varepsilon_m)$，其中$G=(N,E)$，$\varepsilon_m$为阈值}\\\hline
1: & Compute each $r_0(n)$ and $p(m,n)$, initialize $i\gets 0$ \\
2: & while $\varepsilon < {\varepsilon}_m$ do \\
3: & \qquad $\varepsilon \gets 0$ \\
4: & \qquad for all $n \in N$ do \\
5: & \qquad \qquad $r_{i+1}(n) \gets \sum_{m\in N}p(m,n)\cdot r_i(m)$ \\
6: & \qquad \qquad $\varepsilon \gets \varepsilon + \|r_{i+1}(n)-r_i(n)\|$ \\
7: & \qquad \qquad $i \gets i + 1$ \\
8: & \qquad end for \\
9: & end while \\\hline
\end{tabular}
\caption{动态服务均衡算法}
\label{tab:dsba}
\end{table}

\par
动态服务均衡算法在虚拟网络嵌入中扮演着非常重要的角色。假设在底层物理网络中存在两个节点，它们可用的资源是完全相同的，然后，它们的邻居的可用资源，或者它们的邻居的邻居的可用资源却大不相同。此时，为了增加嵌入映射的成功概率，并减少虚拟链路在底层物理网络中的路径长度，我们宁愿选择其邻近节点具有更多资源的节点，也就是具有更高服务能力的节点。事实上，一个具有较高服务能力的底层节点至少满足以下两点中的任一点：
\par
1）节点自身有丰富的资源
\par
2）节点的邻居有丰富的资源
\par
这些原因让我们更加相信那些具有较高服务能力的底层节点，其成功嵌入的概率也会更高。同时，“能者多劳”的思想使得一个成功的嵌入有更好的负载均衡效果。同样地，我们认为高服务能力的虚拟节点具有优先嵌入权，因为当该节点嵌入失败的时候，它可以提前告知整个虚拟网络请求的失败。
\subsection{局部子请求映射}
如图\ref{fig:procedure}所示，每个虚拟网络子请求的嵌入映射是在局部嵌入阶段完成的。经过全局处理后，虚拟网络请求被聚类分割为多个规模较小的子请求，再经过简化处理后，各个子请求变得相互独立。因此，我们可以并发地处理多个子请求。在对子请求进行局部嵌入时，主要采用贪心策略。贪心策略以节点的动态服务能力为参考依据，优先将子请求中具有最大动态服务能力的虚拟节点映射到对应的区域底层物理网络中具有最大动态服务能力的底层节点上。局部嵌入的具体算法描述如表\ref{tab:local algo}所示。由此可知，所有虚拟网络子请求嵌入处理的时间复杂度为~$O(max_{0\leq i < |O^s|}(|N_i^v|^2 \cdot (|N_i^s|log|N_i^s| + |E_i^s|)))$~。
\begin{table}[h]
\centering
\begin{tabular}{r|p{0.9\textwidth}}
\hline
\multicolumn{2}{l}{局部嵌入算法：$LocalEmbed(G_i^s, G_i^v)$}\\\hline
 1.& 对~$G_i^s$~和~$G_i^v$~应用动态服务均衡分析，计算各节点的动态服务能力，时间复杂度为~$O(|N_i^s|log|N_i^s|)$~，其中~$O(|N_i^s|) > O(|N_i^v|)$~；\\\hline
2. & 从具有最高动态服务能力的虚拟节点~$n^v$~开始，依次处理所有未嵌入的虚拟节点，直到所有虚拟节点都被嵌入为止；\\\hline
2.1. & 从区域底层物理网络中选择最多~$k$~个最高动态服务能力的候选节点，这些候选节点都能满足节点~$n^v$~的需求限制。时间复杂度为~$O(N_i^s)$~； \\\hline
2.2. & 找出每个候选节点到已映射节点之间的最短路径，并计算总的路径开销，时间复杂度为~$O(|N_i^v|\cdot(|N_i^s|log|N_i^s|) + |E_i^s|)$~； \\\hline
2.3. & 在~$k$~个候选节点中，找出具有最小的总的路径开销的底层节点~$n^s$~，时间复杂度为~$O(k)$~； \\\hline
2.4. & 将虚拟节点~$n^v$~映射到底层节点~$n^s$~上，同时完成已映射节点到~$n^s$~节点之间的链路映射，时间复杂度为~$O(|E_{neigh}^v(n^v)|)$~； \\\hline
3. & 当所有的虚拟节点都成功映射后，分配实际的资源以提供服务，时间复杂度为~$O(|N_i^v| + |E_i^v|)$~；\\\hline
\end{tabular}
\caption{虚拟网络嵌入的局部嵌入算法}
\label{tab:local algo}
\end{table}

\section{仿真验证}
\label{sec:vne-fangzhen}
\subsection{仿真环境}
为了评估本章提出的面向媒体业务的虚拟网络嵌入算法，~MSO-VNE~，本节将详细介绍我们为该算法设计的仿真实验。在仿真实验中，我们设计并实现了离散事件模拟器，以更贴近现实的方式模拟虚拟网络请求的到来和被处理的过程。仿真实验可以有效地评估虚拟网络嵌入算法的性能，也为虚拟网络嵌入算法在工程中的实际应用提供依据和保障。
\par
在实际生活中，真实的底层物理网络基础设施的拓扑是很难获取的，同时，虚拟网络请求的拓扑也很难得到。因此，本节采用人工合成的网络拓扑，我们使用的合成工具是~GT-ITM (Georgia Tech Internetwork Topology Models)，~该拓扑生成器可以用来生成以平面随机图和层次图作为模型的网络拓扑。最简单的平面随机图模型是纯随机模型：结点在平面上随机分布，任意两个结点间有边的概率为~$a$~。纯随机模型非常简单，且不能很好地反映现实网络的拓扑结构，所以在此基础上又提出了几种平面随机图模型：
\par
1）~Waxman 1~模型\par
该模型中，从结点~$u$~到~$v$~有边的概率为~$P(u,v)=a*e^{-d/(bL)}$~，其中~$0<a,b\leq1$~，~$d$~是两结点间的距离，~$L=\sqrt{2}*scale$~是平面上任意两结点间的最大距离。~$a$~增大则图中边的数目会增大，~$b$~增大则图中长边数与短边数的比值会增大。\par
2）~Waxman 2~模型\par
该模型和~Waxman 1~模型很相似，将~Waxman 1~模型中的参数~$d$~的取值范围变为~$0$~到~$L$~之间的随机数即是~Waxman 2~模型。\par
3）~Doar-Leslie~模型\par
该模型和~Waxman 1~模型很相似，将~Waxman 1~模型中得到的概率值~$P(u,v)$~乘以一个比例因子~$ke/n$~便是~Doar-Leslie~模型。其中~$e$~ 是结点度数的期望值，~$n$~是结点数，~$k$~是由~$a$~，~$b$~共同决定的常数。\par
4）指数模型\par
在指数模型中，从结点~$u$~到~$v$~有边的概率为~$P(u,v)=a*e^{-d/(L-d)}$~，由此可知，节点间有边的概率随着节点间距离的增加而成指数级的降低。\par
5）~Locality~模型\par
在Locality模型中，根据两结点间的距离将结点对分成不同的等级，不同等级的结点对之间有边的概率不同。譬如在两级模型中的分级概率模型如下：\par
$$P(u,v)=\left\{
\begin{array}{c l}
    a, & d < L*radius\\
    b, & d \geq L*radius
\end{array}\right.$$
\par
也就是说，如果节点~$u$~和~$v$~之间的距离~$d$~满足~$d<L*radius$~，则节点~$u$~和~$v$~之间有边的概率为~$P(u,v)=a$~，否则节点间有边的概率为~$P(u,v)=b$~，其中~$radius$~ 用来确定分级界限。\par
平面随机图是层次图的基础，层次图一般由多个平面随机图组成，~GT-ITM~中的层次图主要包括两类：~N-Level~和~Transit-Stub~。其中~N-Level~采用递归的方式来生成网络拓扑图：首先用上述六种随机图模型中的任一种生成一个平面随机图，作为首层图；然后用平面随机图代替首层图中的每一个结点，并且依次替代下去。在~Transit-Stub~中，将结点划入不同类型的域，再将这些域连接起来：首先生成一个平面随机图，图中的每一个结点代表一个~transit~域；然后用平面随机图代替这些~transit~域，表示这些~transit~域的骨干拓扑；对~transit~域中的每个结点，生成一个或多个随机平面图作为~stub~域，并将其和结点连接起来；最后还可以在特定的结点对之间增加一些额外边，这些结点对需满足：一个在~transit~域一个在~stub~域，或者在不同的~stub~域。
\par
在仿真实验中，我们采用~Transit-Stub~模型构建底层物理网络拓扑，采用平面随机图模型合成虚拟网络请求。我们构建了~3~个区域底层物理网络和成千上万个虚拟网络请求。其中，每个区域底层物理网络包含~50~ 个节点，覆盖~$80\times80$~的网格区域。同时，我们假定不同的区域底层网络网络通过~Internet~互联互通，考虑到~Internet~ 的复杂性和不可控制性，我们假定~Internet~有无限的链路资源。为了使我们的仿真实验更接近真实情景，我们设定虚拟网络请求的到达服从泊松分布，平均到达速率是每~100~个时间单位~4~到~8~个请求不等。每个虚拟网络请求的生存周期服从平均时间为~1000~个时间单位的指数分布，且每个虚拟网络请求的节点数量是~2~到~10~的均匀分布。
\par
仿真实验的主要目的是评估面向媒体业务的虚拟网络嵌入算法~MSO-VNE~ 的性能，因此，实验参照对象是必不可少的。我们在仿真实验中选择的参照对象是现有的~D-ViNE~算法和~R-ViNE~算法，主要的评估指标包括时间复杂度、负载分布、平均收益开销比和平均接受率。为了更真实准确地评估~MSO-VNE~算法的性能，我们在相同的仿真环境下对同样的数据集应用以上三种不同的虚拟网络嵌入算法。
%\subsection{性能评估}
\subsection{时间复杂度}
虚拟网络嵌入问题是典型的NP难问题，其时间复杂度非常高。因此，现有的研究大多倾向于设计启发式算法来解决。譬如，~D-ViNE~算法和~R-ViNE~算法就是典型的基于启发式的虚拟网络嵌入算法。我们先来详细分析~D-ViNE~算法的时间复杂度。
\par
~D-ViNE~算法是协调了节点映射和链路映射的虚拟网络嵌入算法，该算法首先会结合虚拟网络请求构建增强的底层物理网络拓扑，这一步骤的时间复杂度为~$O(|N^v|)$~。 然后，~D-ViNE~ 算法将着力解决整数线性规划问题，其时间复杂度为~$O((|E^s|(1+|E^v|))^{3.5}L^2lnLlnlnL)$~。最后，~D-ViNE~算法将以时间复杂度~$O((|E^s||E^v|)^{3.5}L^2lnLlnlnL)$~来解决链路映射相关的~MCF~问题。由此可知，在~D-ViNE~算法中，整数线性规划问题是其复杂度最高的部分，它也就是整个~D-ViNE~算法的时间复杂度。
\par
在面向媒体业务的虚拟网络映射算法~MSO-VNE~中，全局处理阶段将虚拟网络请求划分为多个规模较小的子请求，相比原始的虚拟网络请求，对规模较小的子请求进行嵌入处理具有更低的时间复杂度。同时，局域嵌入阶段可并发地嵌入多个子请求，便进一步降低了虚拟网络嵌入处理的时间复杂度。如表\ref{tab:local algo}所示，面向媒体业务的虚拟网络嵌入算法~MSO-VNE~的时间复杂度为：
$$O(\max_{0\leq i < |O^s|}(|N_i^v|^2 \cdot (|N_i^s|log|N_i^s| + |E_i^s|)))$$
\par
即使在最坏的情况下，当所有的区域底层物理网络都位于同一个地理位置时，虚拟网络嵌入算法的时间复杂度演变为：
$$O(|N^v|^2 \cdot (|N^s|log|N^s| + |E^s|))$$
\par
由于底层物理网络和虚拟网络请求都是连通图，满足~$O(|N|)<O(|E|)$~，因此，虚拟网络嵌入算法~MSO-VNE~的时间复杂度可简化为：
$$O(|E^v|^2 \cdot |E^s|log|E^s)$$
\par
与现有的~D-ViNE~算法相比，很显然，我们提出的~MSO-VNE~算法具有更低的时间复杂度。

\subsection{负载分布}
负载分布包括底层物理网络中物理节点上的负载分布和物理链路上的负载分布。负载分布主要衡量在一段时间内，底层物理网络中各个物理节点和链路上的负载情况，以及全部物理节点和链路上的负载分布情况。
\par
对于~SuperNova~服务虚拟化平台而言，虚拟网络请求就是底层物理网络的负载。具体而言，虚拟网络请求中的节点会根据其需求限制占用底层物理网络中节点的资源，如~CPU~资源、存储资源等；同时，虚拟网络请求中的链路也会根据其需求限制占用底层物理网络中链路的资源，如带宽资源等。由于嵌入算法和部署策略的不同，导致这些虚拟节点负载和虚拟链路负载在底层物理网络中的分布各不相同。因此，衡量负载分布的具体情况，可以窥见虚拟网络嵌入算法的性能。
\par
需要注意的是，虚拟网络嵌入问题是动态问题。随着时间的推移，新的虚拟网络请求会到达底层物理网络并占用底层物理网络资源，同时，过期的虚拟网络请求会随着其生命周期的结束会离开底层物理网络并释放其占用的资源。因此，底层物理网络中的资源使用情况是动态变化的。另外，由于我们假定虚拟网络请求的到达服从泊松分布，虚拟网络请求的生命周期服从指数分布。因此，底层物理网络中总体资源的使用情况在动态变化中能保持基本平稳，这可从仿真实验结果图~\ref{fig:nb}~和图~\ref{fig:eb}~中看出。
\par
仿真实验还可反映出虚拟网络嵌入算法的性能。从实验结果图中，我们可以看出，~MSO-VNE~算法具有更好的均衡负载分布能力。如图~\ref{fig:nb}~和图~\ref{fig:eb}~所示，在~MSO-VNE~算法中，底层物理资源使用得最多和最少的底层物理网络节点和链路的比例都要明显低于在其他两个算法。换句话说，在~D-ViNE~ 算法和~R-ViNE~算法中，存在更多的资源利用不合理的底层物理节点和链路，其利用不合理性在于：这些节点资源和链路的资源要么被过度使用，要么没有得到充分地利用。
\par
综上所述，面向媒体业务的虚拟网络嵌入算法~MSO-VNE~相比于~D-ViNE~ 算法和~R-ViNE~算法具有更好的负载均衡能力，~MSO-VNE~算法使得虚拟网络请求中的节点负载和链路负载在底层物理网络中的分布更均衡，从而提升了底层物理网络中的资源利用率。
\begin{figure}[h]
\includegraphics[width=\textwidth]{nb.eps}
\caption{底层物理网络中的节点负载分布}
\label{fig:nb}
\end{figure}

\begin{figure}[h]
\includegraphics[width=\textwidth]{eb.eps}
\caption{底层物理网络中的链路负载分布}
\label{fig:eb}
\end{figure}

\subsection{平均收益开销比}
在虚拟网络嵌入问题中，存在“收益”和“开销”两个概念。收益是指当成功嵌入一个虚拟网络请求后，底层物理网络因承载该虚拟网络请求获得的收益。开销是指当成功嵌入一个虚拟网络请求后，底层物理网络因承载该虚拟网络请求的资源开销。通常，对于节点而言，其收益和开销是相同的。譬如虚拟节点需要~50M~存储空间，为了承载该虚拟节点，底层物理网络需要分配~50M~的存储空间给该虚拟节点，不管是从一个底层节点上分配~50M~存储空间，还是多个底层节点共同凑齐~50M~存储空间。底层物理网络的收益和开销都是~50M~的存储空间，因此，其收益和开销是相同的，收益开销比为：收益/开销~$=1$~，且保持恒定不变。\par
对于链路而言，收益和开销就不一定相同了。在虚拟网络嵌入中，可能存在跨过节点的链路映射，即虚拟链路可能会被映射到由多条底层物理链路组成的路径上，该路径中的某些节点并没有被用于承载任何虚拟节点。在这种情况下，底层物理网络中的链路开销将大于该底层物理网络的链路收益。如图~\ref{fig:vne-rcr}~所示，当虚拟网络请求嵌入到底层物理网络中时，物理路径$<E,D,C>$上的节点~$D$~并没有用于承载任何虚拟节点，因为其节点资源不足以承载虚拟网络请求中的任何一个虚拟节点。此时，底层物理网络中的链路开销为~$<a,b> + 2 ~ \ast <b,c> + <a,c> = 67$~，而链路收益只有~$<a,b> + <b,c> + <a,c> = 52$~。因此，底层物理网络中的链路收益开销比为~$52/57=0.78$~。
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{vne-rcr.eps}
\caption{虚拟网络嵌入中的链路收益开销示意图}
\label{fig:vne-rcr}
\end{figure}
\par
作为基础设施提供者，追求的是将底层物理网络的利益最大化，希望在相同的底层物理网络上嵌入部署更多的虚拟网络请求，追求收益开销比最大化。如图~\ref{fig:rcr}~所示的仿真实验结果表明，在三个虚拟网络嵌入算法中，我们提出的~MSO-VNE~算法有最高的平均收益开销比，这就意味着~MSO-VNE~算法获得相同的收益只需要更少的开销，或者说在相同的开销下可以获得更多的收益。
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{rcr.eps}
\caption{平均收益开销比对比结果}
\label{fig:rcr}
\end{figure}
\par
~MSO-VNE~算法的高平均收益开销比来源于局域嵌入阶段的动态负载均衡分析。在动态负载均衡分析中，通过引入动态服务能力来评估节点的重要性，由于动态服务能力不仅考虑了节点自身的资源，还考虑了邻居节点的资源，再加上贪心部署策略的实施，使得虚拟网络嵌入能有效地避免孤立嵌入问题。孤立嵌入是指将虚拟网络请求中的某个虚拟节点嵌入到底层物理网络中孤立的物理节点上的情形。孤立的物理节点是指那些自身拥有丰富的资源，但是其邻居节点的资源几被消耗殆尽的节点。当存在孤立嵌入时，为了完成整个虚拟网络请求的嵌入，必然存在很多跨越节点的链路映射，从而增加了虚拟链路映射的底层路径长度，使得链路的开销增大。
\par
在~MSO-VNE~算法中，局域嵌入阶段引入的动态服务能力和贪心策略可保证虚拟链路尽可能被映射到底层物理网络中的较短路径上。因此，底层物理网络在承载该虚拟网络请求时，采用~MSO-VNE~算法将导致虚拟链路映射的底层物理路径长度减少。由于链路收益是不变的，链路开销的降低使得底层物理网络的链路收益开销比得到增加。

\subsection{平均接受率}
平均接受率衡量的是在一段时间内被底层物理网络接受的请求在总请求中的比例。由于虚拟网络嵌入的动态性，底层物理网络中的资源使用情况是动态变化的。动态性即随着时间的推移，新的虚拟网络请求会到达底层物理网络并占用底层物理网络资源，同时，过期的虚拟网络请求会随着其生命周期的结束而离开底层物理网络并释放其占用的资源。另外，虚拟网络嵌入又是基本平稳的，因为虚拟网络请求的到达服从泊松分布，同时，虚拟网络请求的生命周期服从指数分布。因此，平均接受率在足够长的时间后也是保持基本平稳的。
\par
如图\ref{fig:accept}所示的仿真实验结果图表明，在所有的算法中，~MSO-VNE~ 算法具有最高的平均接受率。即在相同的环境下，~MSO-VNE~算法能够接受并容纳的虚拟网络请求数绝不会比其他的算法少。
\par
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{accept.eps}
\caption{平均接受率对比结果}
\label{fig:accept}
\end{figure}
\par
~MSO-VNE~算法的高平均接受率是很容易理解的。直观地，~MSO-VNE~算法的高平均收益开销比说明该算法在相同的收益下，只需要更少的资源开销。这就意味着剩余的资源可以用来嵌入更多的虚拟网络请求，久而久之，底层物理网络便能接受并容纳更多的虚拟网络请求，即具有更高的平均接受率。
\subsection{小结}
仿真实验结果表明，相比于~D-ViNE~算法和~R-ViNE~算法，本章提出的面向媒体业务的虚拟网络嵌入算法~MSO-VNE~具有很出色的性能表现：更低的时间复杂度、底层物理网络中更均衡的负载分布、更高的平均收益开销比和更高的平均接受率。~MSO-VNE~算法的出色性能，一方面得益于全局处理阶段采用的分而治之思想和并发处理思想：通过将虚拟网络请求聚类分割为规模较小的子请求，并将各个子请求分派到离它最近的区域底层物理网络中进行并发处理，从而大大降低了时间复杂度。另一方面得益于局域嵌入阶段的动态负载均衡分析：通过引入动态服务能力来评估节点的重要性，不仅考虑节点自身的资源承载能力，还兼顾邻居节点的资源承载能力，为整个虚拟网络请求的成功和优化嵌入提供了保障，在改善了底层物理网络的负载分布情况和资源利用率的情况下，大大减少了链路映射开销，提高了平均收益开销比和平均接受率。

\section{面向媒体业务的资源映射交互框架}
\label{sec:vne-kuangjia}
基于面向媒体业务的虚拟网络嵌入算法~MSO-VNE~，本节提出了面向媒体业务的资源映射交互框架，~MSO-VNE~算法负责处理该交互框架的资源映射，是该交互框架的核心模块。本节将详细介绍面向媒体业务的资源映射交互框架，包括系统框架和各部分的组件模块。
\subsection{系统框架}
在面向媒体业务的资源映射交互框架中，~MSO-VNE~算法是其核心模块。尽管虚拟网络嵌入问题起源于网络虚拟化，但它仍然属于资源管理领域，因此，可将其应用到资源映射交互框架中处理资源映射问题。本章提出的~MSO-VNE~算法是面向媒体业务的，因此，将其应用到面向媒体业务的资源映射管理中，可以保障媒体服务的~QoS~服务质量需求。
\par
如图\ref{fig:framework}所示，资源映射交互框架主要包括以下几个模块：
\par
\textbf{1）用户接口模块}\par
该模块是资源映射交互框架中面向用户的部分，用户通过该模块中的相应组件以命令行方式或Web页面方式定义其业务需求和服务请求，通过提交请求以获取特定的服务。
\par
\textbf{2）预处理模块}\par
预处理模块的主要职责是对用户提交的请求进行预处理，使得该请求不仅是人类可理解的，更是计算机可理解的。
\par
\textbf{3）资源映射模块}\par
资源映射模块是资源映射交互框架的核心模块。在该模块中，面向媒体业务的虚拟网络嵌入算法~MSO-VNE~被采用以处理该框架中的资源映射问题，通过将用户的业务请求和底层物理网络的可用资源进行匹配计算和映射处理，完成资源的映射。
\par
\textbf{4）资源分配模块}\par
资源分配模块是资源映射模块的补充。当用户提交的业务请求和底层物理网络的可用资源成功映射后，资源分配模块便开始工作， 它根据资源映射模块的映射结果进行真正的资源分配工作。
\par
\textbf{5）资源监控模块}\par
资源监控模块是辅助模块，它可以辅助资源映射模块和资源分配模块完成它们的工作。资源映射模块通过资源监控模块获取底层物理网络中的可用资源数量，以辅助资源映射工作。资源分配模块通过资源监控模块获取并分配实际的资源。资源监控模块通过实时监控底层资源池中的资源使用变化情况并进行必要的同步管理。

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{framework.eps}
\caption{面向媒体业务的资源交互系统框架}
\label{fig:framework}
\end{figure}
\par
从整体来看，面向媒体业务的资源映射交互框架可以分为两层：用户层和系统层。其中，用户层的设计是面向业务用户的，用户通过定义他们的业务需求并提交请求，然后，这些业务需求会被分析和处理。当然，任何请求的具体的分析和处理都是在系统层进行的，而系统层对用户是透明的。用户层的设计宗旨是让用户专注在他们所关心的业务和服务上，而不是任何其他的琐碎细节，如怎样进行请求预处理，如何执行映射抑或如何分配或监控资源。这些琐碎的细节都是有系统层来处理的。
\par
当用户的请求到达时，系统层开始工作。首先，系统层执行预处理以从用户提交的业务需求请求中提取有用的信息并分析用户的业务需求。系统层的核心是资源映射，在资源映射模块中，我们采用了~MSO-VNE~算法以执行映射匹配。通过资源监控模块，可以获取系统的可用资源，如果系统有足够的资源，用户的请求就会得到成功的匹配。当成功匹配后，资源分配子模块会为用户分配实际的资源。当然，不管是否能够成功映射，系统层都会将处理结果反馈给用户层。反馈对系统是有用的，不仅可以告诉用户请求的处理结果，还可以辅助用户做更好的决策。
\par
下面，我们将详细描述资源映射交互框架中的各个模块设计。
\subsection{交互框架设计细则}
\subsubsection{用户接口模块}
用户接口模块是面向用户的，其战略目标是简化用户操作，提升用户体验质量。用户接口模块的设计主要考虑以下几个子模块：
\par
\textbf{1）功能定义}\par
功能定义子模块的主要用途是定义系统可能提供的功能。实际上，功能定义子模块和具体的应用场景密切相关。一个良好的功能定义子模块可以清晰地将系统及其提供的功能呈现在用户面前，很好地回答“系统是什么”以及“系统能做什么”等类似的问题，留给用户良好的第一印象，并以提高用户体验质量为宗旨。
\par
\textbf{2）交互设计}\par
交互设计子模块主要解决的是如下问题：用户如何与系统进行通信和交流、如何实现良好的人机交互等问题。常见的交互方式包括命令行客户端工具、~Web~网页交互等。相比较而言，命令行客户端工具具有简洁准确和快速的特点，但他稍显复杂的操作方式显然比不上Web页面的可视化交互方式。不管采用哪种交互方式，都必须做到意图明了、操作简单和快速响应。
\par
\textbf{3）反馈设计}\par
广义上来说，反馈设计子模块也可以算做是交互设计的一部分。反馈设计的重点在于系统将处理结果告知并反馈给提交请求的用户。通过将最终的处理结果反馈给用户，以指导用户做进一步的决策。
\par
\textbf{4）页面布局}\par
页面布局子模块子针对Web网页交互方式。简单来说，页面布局子模块就是合理安排组件元素的呈现方式，如何将系统功能、交互元素等合理地组合布局，如何突出系统的重点，如何吸引用户的注意力等。

\subsubsection{预处理模块}
预处理模块是在进行资源映射前，对用户提交的业务请求进行适当的整理和预处理。预处理模块主要包含如下几个子模块：
\par
\textbf{1）信息抽取}\par
信息抽取子模块通过从用户提交的业务请求中抽取出系统需要的有用的信息，剔除冗余的信息，以减小处理复杂度并提高效率。
\par
\textbf{2）需求解析}\par
需求解析子模块通过对需求进行分类处理以及编排合理的信息呈现方式，对需求信息进行基本的预处理和解析。

\subsubsection{资源映射模块}
资源映射模块是资源映射交互框架的核心，经过上述几个模块的处理，用户提交的业务需要被合理的解析和处理，能够被计算机识别和理解。此时，资源映射模块获取系统的可用资源，并进行映射匹配计算。资源映射模块主要包括以下几个子模块：
\par
\textbf{1）资源获取}\par
资源获取子模块在资源监控模块的辅助下，获取系统的资源使用情况和可用资源，为映射匹配做好充分的准备。
\par
\textbf{2）映射匹配}\par
映射匹配子模块的主要任务是将用户的请求和系统的可用资源进行匹配计算。在这里，我们采用的是本节提出的面向媒体业务的虚拟网络嵌入算法~MSO-VNE~，上节的仿真实验已验证了该算法的出色性能。

\subsubsection{资源监控}
资源监控模块主要包括以下几个子模块：
\par
\textbf{1）监控}\par
\textbf{2）同步管理}\par
顾名思义，资源监控模块就是监控资源池中资源的变化，并进行同步和更新管理。
\subsubsection{资源分配}
资源分配模块主要包括以下几个子模块：
\par
\textbf{1）分配}\par
\textbf{2）同步管理}\par
资源分配模块的功能很直接明确：当映射成功的时候，为用户的请求分配真正的资源以为其提供服务。并保持资源池中资源的同步和更新操作。

\section{小结}
\label{sec:vne-xiaojie}
本章提出了面向媒体业务的虚拟网络嵌入算法~MSO-VNE~，并详细阐述了算法的主要思想和技术实现细节。~MSO-VNE~算法根据虚拟网络请求和底层物理网络的地理位置特征，应用节点聚类算法，充分利用了分而治之思想和并发处理思想的优势，显著地降低虚拟网络嵌入处理的时间复杂度。同时，本章提出的~MSO-VNE~算法在局域嵌入阶段应用了动态服务均衡分析，充分考虑了节点在网络拓扑中的重要性，引入动态服务能力，通过贪心策略进行嵌入映射。
\par
为了评估本章提出的面向媒体业务的虚拟网络嵌入算法~MSO-VNE~的性能，我们设计了仿真实验，将~MSO-VNE~算法与已有的~D-ViNE~算法和~R-ViNE~算法进行性能对比。仿真实验的结果表明本章提出的~MSO-VNE~ 算法具有很出色的性能：更低的时间复杂度、更好的负载均衡、更高的平均收益开销比和更高的平均接受率。
\par
虽然，VNE问题起源于网络虚拟化，但它仍属于资源分配和管理领域。因此，本章提出了面向媒体业务的资源映射交互框架，在该资源映射交互框架中，本章提出的~MSO-VNE~算法被采用，作为该资源映射交互框架的资源映射核心组件模块。~MSO-VNE~算法在仿真实验中表现出的良好性能，给了我们很大的信心，使我们更加相信基于~MSO-VNE~算法的资源映射交互框架可以获得更好的~QoS~服务质量和更好的用户体验质量。
